{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use from keras.datasets import fashion_mnist for getting the fashion mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: fwwuthks\n",
      "Sweep URL: https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'accuracy', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'learning_rate': {'values': [1e-3,1e-4]},\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [5, 10]},\n",
    "        'hidden_layers': {'values': [3,4,5]},\n",
    "        'hidden_size': {'values': [32, 64,128]},\n",
    "        'activation': {'values': ['relu', 'sigmoid','tanh']},\n",
    "        'optimizer': {'values': ['sgd', 'momentum','nesterov','rmsprop','adam','nadam']},\n",
    "        'weight_init': {'values': ['random', 'xavier']},\n",
    "        'weight_decay': {\"values\": [0,0.0005,0.5]}\n",
    "    },\n",
    "    \"run_cap\":100\n",
    "}\n",
    "\n",
    "# wandb.init(project=\"Assignment - 1\")  # Ensure WandB is initialized before using config\n",
    "# wandb.login()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DLA1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"DLA1\", entity=\"da24m014-iit-madras\")\n",
    "\n",
    "# # Load the Fashion-MNIST dataset\n",
    "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "# # Class names for Fashion-MNIST\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "#                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# # Log sample images to wandb\n",
    "# sample_images = []\n",
    "# unique_classes = np.unique(y_train)\n",
    "\n",
    "# for cls in unique_classes:\n",
    "#     sample_idx = np.where(y_train == cls)[0][0]  # Find an example for the class\n",
    "#     img = x_train[sample_idx]\n",
    "    \n",
    "#     sample_images.append(wandb.Image(img, caption=class_names[cls]))\n",
    "\n",
    "# # Log images to wandb\n",
    "# wandb.log({\"Sample Images\": sample_images})\n",
    "\n",
    "# # Finish wandb run\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    encoded = np.zeros((y.size,num_classes))\n",
    "    encoded[np.arange(y.size),y] = 1\n",
    "    return encoded\n",
    "\n",
    "y_train, y_test = one_hot_encode(y_train,num_classes), one_hot_encode(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(0.9*len(x_train))\n",
    "x_train, x_val = x_train[:split_idx], x_train[split_idx:]\n",
    "y_train, y_val = y_train[:split_idx], y_train[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    Z = np.clip(Z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def tanh(Z):\n",
    "    return np.tanh(Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "activation_functions = {\"relu\": relu, \"sigmoid\": sigmoid, \"tanh\": tanh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Stochastic Gradient Descent (SGD)\n",
    "def sgd_update(weights, biases, grads_W, grads_b, learning_rate):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= learning_rate * grads_W[i]\n",
    "        biases[i] -= learning_rate * grads_b[i]\n",
    "\n",
    "# Momentum Optimizer\n",
    "def momentum_update(weights, biases, grads_W, grads_b, learning_rate, velocity_W, velocity_b, momentum=0.9):\n",
    "    for i in range(len(weights)):\n",
    "        velocity_W[i] = momentum * velocity_W[i] - learning_rate * grads_W[i]\n",
    "        velocity_b[i] = momentum * velocity_b[i] - learning_rate * grads_b[i]  # Corrected\n",
    "\n",
    "        weights[i] += velocity_W[i]\n",
    "        biases[i] += velocity_b[i] # Fixed Bias Update\n",
    "\n",
    "# Nesterov Accelerated Gradient (NAG)\n",
    "def nesterov_update(weights, biases, grads_W, grads_b, learning_rate, velocity_W,velocity_b, momentum=0.9):\n",
    "    for i in range(len(weights)):\n",
    "        # Compute lookahead position\n",
    "        lookahead_W = weights[i] + momentum * velocity_W[i]\n",
    "        lookahead_b = biases[i] + momentum * velocity_b[i]  # Corrected\n",
    "\n",
    "        # Update velocity\n",
    "        velocity_W[i] = momentum * velocity_W[i] - learning_rate * grads_W[i]\n",
    "        velocity_b[i] = momentum * velocity_b[i] - learning_rate * grads_b[i]  # Corrected\n",
    "\n",
    "        # Update weights and biases with corrected lookahead step\n",
    "        weights[i] = lookahead_W + velocity_W[i]\n",
    "        biases[i] = lookahead_b + velocity_b[i]\n",
    "\n",
    "# RMSprop Optimizer\n",
    "def rmsprop_update(weights, biases, grads_W, grads_b, learning_rate, velocity_W, velocity_b, beta=0.9, epsilon=1e-6):\n",
    "    for i in range(len(weights)):\n",
    "        # Update velocity for weights and biases separately\n",
    "        velocity_W[i] = beta * velocity_W[i] + (1 - beta) * (grads_W[i] ** 2)\n",
    "        velocity_b[i] = beta * velocity_b[i] + (1 - beta) * (grads_b[i] ** 2)\n",
    "\n",
    "        # Update weights\n",
    "        weights[i] -= learning_rate * grads_W[i] / (np.sqrt(velocity_W[i]) + epsilon)\n",
    "\n",
    "        # Update biases\n",
    "        biases[i] -= learning_rate * grads_b[i] / (np.sqrt(velocity_b[i]) + epsilon)\n",
    "\n",
    "# Adam Optimizer\n",
    "# Adam Optimizer\n",
    "def adam_update(weights, biases, grads_W, grads_b, learning_rate, velocity_W, velocity_b, moment2_W, moment2_b, beta1=0.9, beta2=0.999, epsilon=1e-6, t=1):\n",
    "    for i in range(len(weights)):\n",
    "        # First moment estimate\n",
    "        velocity_W[i] = beta1 * velocity_W[i] + (1 - beta1) * grads_W[i]\n",
    "        velocity_b[i] = beta1 * velocity_b[i] + (1 - beta1) * grads_b[i]\n",
    "\n",
    "        # Second moment estimate\n",
    "        moment2_W[i] = beta2 * moment2_W[i] + (1 - beta2) * (grads_W[i] ** 2)\n",
    "        moment2_b[i] = beta2 * moment2_b[i] + (1 - beta2) * (grads_b[i] ** 2)\n",
    "\n",
    "        # Bias correction\n",
    "        velocity_W_corrected = velocity_W[i] / (1 - beta1 ** t)\n",
    "        velocity_b_corrected = velocity_b[i] / (1 - beta1 ** t)\n",
    "\n",
    "        moment2_W_corrected = moment2_W[i] / (1 - beta2 ** t)\n",
    "        moment2_b_corrected = moment2_b[i] / (1 - beta2 ** t)\n",
    "\n",
    "        # Check and correct shape mismatch\n",
    "        if moment2_b_corrected.shape != biases[i].shape:\n",
    "            print(f\"Shape mismatch at layer {i}: {moment2_b_corrected.shape} vs {biases[i].shape}\")\n",
    "            moment2_b_corrected = np.reshape(moment2_b_corrected, biases[i].shape)\n",
    "\n",
    "        # Parameter update\n",
    "        weights[i] -= learning_rate * velocity_W_corrected / (np.sqrt(moment2_W_corrected) + epsilon)\n",
    "        biases[i] -= learning_rate * velocity_b_corrected / (np.sqrt(moment2_b_corrected) + epsilon)\n",
    "\n",
    "    return t + 1  # Increment time step\n",
    "\n",
    "def nadam_update(weights, biases, grads_W, grads_b, learning_rate, velocity_W, velocity_b, moment2_W, moment2_b, beta1=0.9, beta2=0.999, epsilon=1e-6, t=1):\n",
    "    for i in range(len(weights)):\n",
    "        # First moment estimate\n",
    "        velocity_W[i] = beta1 * velocity_W[i] + (1 - beta1) * grads_W[i]\n",
    "        velocity_b[i] = beta1 * velocity_b[i] + (1 - beta1) * grads_b[i]\n",
    "\n",
    "        # Second moment estimate\n",
    "        moment2_W[i] = beta2 * moment2_W[i] + (1 - beta2) * (grads_W[i] ** 2)\n",
    "        moment2_b[i] = beta2 * moment2_b[i] + (1 - beta2) * (grads_b[i] ** 2)\n",
    "\n",
    "        # Bias correction\n",
    "        velocity_W_corrected = (beta1 * velocity_W[i] + (1 - beta1) * grads_W[i]) / (1 - beta1 ** t)\n",
    "        velocity_b_corrected = (beta1 * velocity_b[i] + (1 - beta1) * grads_b[i]) / (1 - beta1 ** t)\n",
    "\n",
    "        moment2_W_corrected = moment2_W[i] / (1 - beta2 ** t)\n",
    "        moment2_b_corrected = moment2_b[i] / (1 - beta2 ** t)\n",
    "\n",
    "        # Parameter update\n",
    "        weights[i] -= learning_rate * velocity_W_corrected / (np.sqrt(moment2_W_corrected) + epsilon)\n",
    "        biases[i] -= learning_rate * velocity_b_corrected / (np.sqrt(moment2_b_corrected) + epsilon)\n",
    "\n",
    "    return t + 1  # Increment time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, learning_rate=0.001, activation=\"relu\", optimizer=\"sgd\",\n",
    "                 weight_init=\"random\", weight_decay=0.0, beta=0.5, beta1=0.5, beta2=0.5, epsilon=1e-6):\n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_init = weight_init\n",
    "        self.weight_decay = weight_decay\n",
    "        self.beta = beta\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.init_weights(weight_init)\n",
    "        \n",
    "        # Initialize optimizer-specific parameters\n",
    "        self.velocity_W = [np.zeros_like(W) for W in self.weights]\n",
    "        self.velocity_b = [np.zeros_like(b) for b in self.biases]\n",
    "        self.moment2_W = [np.zeros_like(W) for W in self.weights]  # First moment estimate\n",
    "        self.moment2_b = [np.zeros_like(b) for b in self.biases]  # Second moment estimate\n",
    "        self.t = 0  # Timestep for Adam/Nadam\n",
    "\n",
    "    def init_weights(self, method):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            if method == \"xavier\":\n",
    "                limit = np.sqrt(6 / (self.layers[i] + self.layers[i+1]))\n",
    "            else:  # Default to \"random\"\n",
    "                limit = 0.1\n",
    "            W = np.random.uniform(-limit, limit, (self.layers[i], self.layers[i+1]))\n",
    "            self.weights.append(W)\n",
    "            self.biases.append(np.zeros((1, self.layers[i+1])))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.A = [X]\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            Z = self.A[-1] @ self.weights[i] + self.biases[i]\n",
    "            A = activation_functions[self.activation](Z)\n",
    "            self.A.append(A)\n",
    "        Z = self.A[-1] @ self.weights[-1] + self.biases[-1]\n",
    "        A = softmax(Z)\n",
    "        self.A.append(A)\n",
    "        return A\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        loss = -np.mean(np.sum(y_true * np.log(y_pred + 1e-8), axis=1))\n",
    "        loss += (self.weight_decay / 2) * sum(np.sum(W**2) for W in self.weights)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        grads_W, grads_b = [], []\n",
    "        dA = self.A[-1] - y\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dW = self.A[i].T @ dA / X.shape[0]\n",
    "            db = np.sum(dA, axis=0, keepdims=True) / X.shape[0]\n",
    "            dW += self.weight_decay * self.weights[i]\n",
    "            grads_W.append(dW)\n",
    "            grads_b.append(db)\n",
    "            if i > 0:\n",
    "                dA = (dA @ self.weights[i].T) * (self.A[i] > 0)\n",
    "        return grads_W[::-1], grads_b[::-1]\n",
    "    \n",
    "    def train(self, X_train, y_train, x_val, y_val, epochs, batch_size):\n",
    "        num_samples = X_train.shape[0]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.permutation(num_samples)\n",
    "            X_train, y_train = X_train[indices], y_train[indices]\n",
    "\n",
    "            total_loss, total_acc = 0, 0\n",
    "            num_batches = num_samples // batch_size\n",
    "\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                X_batch = X_train[i:i + batch_size]\n",
    "                y_batch = y_train[i:i + batch_size]\n",
    "                \n",
    "                # Forward Pass\n",
    "                y_pred = self.forward(X_batch)\n",
    "                \n",
    "                # Compute Loss & Accuracy\n",
    "                loss = self.compute_loss(y_batch, y_pred)\n",
    "                acc = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_batch, axis=1))\n",
    "                \n",
    "                total_loss += loss * len(X_batch)\n",
    "                total_acc += acc * len(X_batch)\n",
    "                \n",
    "                # Backward Pass\n",
    "                grads_W, grads_b = self.backward(X_batch, y_batch)\n",
    "                \n",
    "                # Update Weights using the selected optimizer\n",
    "                self.t += 1  # Increment timestep for Adam/Nadam\n",
    "                if self.optimizer == \"sgd\":\n",
    "                    sgd_update(self.weights, self.biases, grads_W, grads_b, self.learning_rate)\n",
    "                elif self.optimizer == \"momentum\":\n",
    "                    momentum_update(self.weights, self.biases, grads_W, grads_b, self.learning_rate, self.velocity_W,self.velocity_b)\n",
    "                elif self.optimizer == \"nesterov\":\n",
    "                    nesterov_update(self.weights, self.biases, grads_W, grads_b, self.learning_rate, self.velocity_W,self.velocity_b)\n",
    "                elif self.optimizer == \"rmsprop\":\n",
    "                    rmsprop_update(self.weights, self.biases, grads_W, grads_b, self.learning_rate, self.velocity_W,self.velocity_b, self.beta, self.epsilon)\n",
    "                elif self.optimizer == \"adam\":\n",
    "                    adam_update(self.weights, self.biases, grads_W, grads_b, self.learning_rate, self.velocity_W,self.velocity_b,self.moment2_W, self.moment2_b, self.beta1, self.beta2, self.epsilon, self.t)\n",
    "                elif self.optimizer == \"nadam\":\n",
    "                    nadam_update(self.weights, self.biases, grads_W, grads_b, self.learning_rate, self.velocity_W,self.velocity_b,self.moment2_W, self.moment2_b, self.beta1, self.beta2, self.epsilon, self.t)\n",
    "            \n",
    "            # Compute average loss and accuracy for the epoch\n",
    "            avg_loss = total_loss / num_samples\n",
    "            avg_acc = total_acc / num_samples\n",
    "\n",
    "            # Validation Metrics\n",
    "            y_val_pred = self.forward(x_val)\n",
    "            val_loss = self.compute_loss(y_val, y_val_pred)\n",
    "            val_acc = np.mean(np.argmax(y_val_pred, axis=1) == np.argmax(y_val, axis=1))\n",
    "\n",
    "            # Log to Weights & Biases\n",
    "            wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss, \"accuracy\": avg_acc, \"val_loss\": val_loss, \"val_accuracy\": val_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0f3ad3tn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m014\u001b[0m (\u001b[33mda24m014-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DLA1' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'da24m014' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\IIT Madras\\SEM 2\\Deep Learning\\Assignment-1-DL\\wandb\\run-20250306_163234-0f3ad3tn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/0f3ad3tn' target=\"_blank\">restful-sweep-1</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/0f3ad3tn' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/0f3ad3tn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▇█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆█▇█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5962</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.98488</td></tr><tr><td>val_accuracy</td><td>0.5903</td></tr><tr><td>val_loss</td><td>0.98973</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_5_bs_32_ac_tanh</strong> at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/0f3ad3tn' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/0f3ad3tn</a><br> View project at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250306_163234-0f3ad3tn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ddma95j8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DLA1' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'da24m014' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\IIT Madras\\SEM 2\\Deep Learning\\Assignment-1-DL\\wandb\\run-20250306_163326-ddma95j8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/ddma95j8' target=\"_blank\">charmed-sweep-2</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/ddma95j8' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/ddma95j8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇█████▇▇▇</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▁▁▁▂▃▃▄▅▅</td></tr><tr><td>val_accuracy</td><td>▁▅█▅▆▃▆▁▇▆</td></tr><tr><td>val_loss</td><td>▃▂▁▄▅▇▅█▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.84146</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.5364</td></tr><tr><td>val_accuracy</td><td>0.8392</td></tr><tr><td>val_loss</td><td>0.59012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_4_bs_32_ac_relu</strong> at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/ddma95j8' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/ddma95j8</a><br> View project at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250306_163326-ddma95j8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i73ylonv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DLA1' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'da24m014' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\IIT Madras\\SEM 2\\Deep Learning\\Assignment-1-DL\\wandb\\run-20250306_163348-i73ylonv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/i73ylonv' target=\"_blank\">toasty-sweep-3</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/i73ylonv' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/i73ylonv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▃▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.86983</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.41989</td></tr><tr><td>val_accuracy</td><td>0.8509</td></tr><tr><td>val_loss</td><td>0.48631</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_64_ac_relu</strong> at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/i73ylonv' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/i73ylonv</a><br> View project at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250306_163348-i73ylonv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xgwurcwi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nesterov\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'DLA1' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'da24m014' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\IIT Madras\\SEM 2\\Deep Learning\\Assignment-1-DL\\wandb\\run-20250306_163409-xgwurcwi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/xgwurcwi' target=\"_blank\">clean-sweep-4</a></strong> to <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/sweeps/fwwuthks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/xgwurcwi' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/xgwurcwi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▁▁▂▂▄▆██</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>████████▆▁</td></tr><tr><td>val_accuracy</td><td>▁▁█▁▁▁▇▇▇▇</td></tr><tr><td>val_loss</td><td>███████▇▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.17985</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>2.1126</td></tr><tr><td>val_accuracy</td><td>0.1813</td></tr><tr><td>val_loss</td><td>2.08743</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_4_bs_16_ac_sigmoid</strong> at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1/runs/xgwurcwi' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1/runs/xgwurcwi</a><br> View project at: <a href='https://wandb.ai/da24m014-iit-madras/DLA1' target=\"_blank\">https://wandb.ai/da24m014-iit-madras/DLA1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250306_163409-xgwurcwi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "def train_with_wandb():\n",
    "    wandb.init(project=\"DLA1\", entity=\"da24m014\") # Ensure WandB is initialized before using config\n",
    "    config = wandb.config\n",
    "    run_name = f\"hl_{config.hidden_layers}_bs_{config.batch_size}_ac_{config.activation}\"\n",
    "    wandb.run.name = run_name\n",
    "    model = NeuralNetwork([784] + [config.hidden_size] * config.hidden_layers + [10],\n",
    "                          learning_rate=config.learning_rate,\n",
    "                          activation=config.activation,\n",
    "                          optimizer=config.optimizer,\n",
    "                          weight_init=config.weight_init,\n",
    "                          weight_decay=config.weight_decay\n",
    "                          )\n",
    "    model.train(x_train, y_train, x_test, y_test, config.epochs, config.batch_size)\n",
    "    # wandb.finish()\n",
    "wandb.agent(sweep_id, function=train_with_wandb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
